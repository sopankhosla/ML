{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from IPython.display import Image \n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ./notMNIST_large.tar.gz\n",
      "Found and verified ./notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'http://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz.\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz.\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABxUlEQVR4nGWRPUjVURjGn/eco3mp\noG4IDdHHUFFDCUofS5hENdQSZEN70FAQBOHglLVGRVtrtjTV0tBgS+B2h6iQJBIUQpSGPuz+z3t+\nDV7vveqzPjwf7/OaumHUHm9DNj4bijYi2iUALihKUlpHws1SJY97ZZvI6IPnrdeIBzd5SkGvqQqZ\nNwqbEnUWBwpztVXfbqF9wJvfKPiAgtQtj+Xq6crePpV7GNjga6H2hYrhEbzi2eotXYm3adLQMScz\nvT7TrL5QKq6rvoizvHudb9QDmuVzn4Vp3BlW7BQKZd+tYvZopafMqhSdkHVIY3x7TnMvU4hfJWlI\nneWjHf/nFTck6TLZmemRtbflfm9OP7+fVMh1BWn/gRljrc0IDrnQgjOq1MokTgi5Ss45Z6SiIbWF\n18i0ZUBmSkEmyay3cQizqY8BSRrth/Dj6LKtDZfdl3a1yk2SKZxSDJJRH8MIT5b6UkqpLzWEigZl\nkqIekr0s7LSWz0WciklFKerwby+Zu60vmfb8oTjzWyWLekd2FvtXhTKlTzjOOVPSPTKZV2szm/Se\nTFVeSLqCQ2bMkjrKAvw6ks48/0tQrs3T/sKO+gom33LnP+c6B4MMFZrGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='notMNIST_small/A/SWFkZWxvbi1EZW1pQm9sZC5vdGY=.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    print \n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52912"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('./notMNIST_large/C.pickle','r')\n",
    "dataset = pickle.load(file)\n",
    "len(dataset)\n",
    "# image = dataset[5]\n",
    "# image\n",
    "# plt.imshow(image, interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (100000, 28, 28) (100000,)\n",
      "Validation: (5000, 28, 28) (5000,)\n",
      "Testing: (5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "#   print(vsize_per_class)\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "#         print(len(letter_set))\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 100000\n",
    "valid_size = 5000\n",
    "test_size = 5000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f7ff630d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f800268d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[23], interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 345400441\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(0, len(valid_dataset)):\n",
    "    for j in xrange(0, len(train_dataset)):\n",
    "        if valid_dataset[i].all() == train_dataset[j].all():\n",
    "            plt.imshow(train_dataset[j], interpolation = 'nearest')\n",
    "        else:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
